{
  "version": "https://jsonfeed.org/version/1",
  "title": "Sean Becker | Feed",
  "home_page_url": "https://seanbecker.me",
  "feed_url": "https://seanbecker.me/feed.json",
  "description": "Technology and Engineering Blog",
  "icon": "https://seanbecker.me/logo.png",
  "items": [
    {
      "id": "https://seanbecker.me/blog/about-me",
      "content_html": "\n- I grew up in Vernon Hills, IL\n- I went to Purdue University where I majored in Computer Science and minored in Business Management\n- I try to take at least one ski trip every year, usually on the west coast of the US\n- I frequently listen to podcasts including Lex Fridman, Andrew Huberman, Joe Rogan, and Sam Harris\n- I enjoy building all things related to technology. Please reach out if you have an idea and want advice on how to build it :)\n\nGo back [home](/).\n",
      "url": "https://seanbecker.me/blog/about-me",
      "title": "About Me",
      "summary": "Just a few snippets of information to get to know me.",
      "date_modified": "2023-12-03T06:00:00.000Z"
    },
    {
      "id": "https://seanbecker.me/blog/past-projects",
      "content_html": "\n<ProjectList filter={({ active }) => !active} />\n\nGo back [home](/).\n",
      "url": "https://seanbecker.me/blog/past-projects",
      "title": "Past Projects",
      "summary": "This is a list of some of the projects I've worked on in the past.",
      "date_modified": "2023-12-03T06:00:00.000Z"
    },
    {
      "id": "https://seanbecker.me/blog/chatgpt-text-completion",
      "content_html": "\nJust looking for code? You can find that [here](https://gist.github.com/seanbecker15/49a20ef17e77682d7907f5eba8fd507b).\n\n## Introduction\n\nThere are lots of things that make ChatGPT great under the hood, but let's face it: most people will never truly understand the internals.\nThat doesn't mean that the entire stack has to be a mystery!\n\n### Why UX is important\n\nIf you've ever used the OpenAI API you'll know that it's quite slow to use the standard API without streaming. It can take 10+ seconds to a receive\na response depending on the complexity of the prompt. Although it is [probably a myth](https://www.reddit.com/r/webdev/comments/n66d0r/comment/gx5b2gl) that users will leave your website if it takes more than 3 seconds to load,\nit is still super important to have good _perceived performance_. For companies working on cutting edge innovation such as OpenAI it is even more important to prove that their tool is useful.\nWaiting for 10+ seconds leads to loss of context and a bad user experience.\n\nThough the total response time is likely the same, the streaming API sends back partial responses as they are generated.\nUsers can see the response in real time and process the response as it is being generated. This makes a huge difference in the user experience.\n\n### Assumptions\n\n- I'm using React for this example, but most of this code should be very easy to plug into other frameworks.\n- I'm assuming that you already have a backend endpoint that forwards the OpenAI stream to your frontend. If not, I will be making a guide on how to do that soon.\n\n### Prerequisites\n\n```bash\nnpm install eventsource-parser\n```\n\n## Let's get coding\n\n1. Scaffold our component. We'll need a prompt input, a submit button, and a location for our results.\n\n```javascript\nimport { useState, ChangeEvent } from \"react\";\n\n// Assumes that you can already fetch a completion from OpenAI\nimport { fetchCompletion } from \"./api\";\n\nconst Chatbot = () => {\n  const [prompt, setPrompt] = useState(\"\");\n  const [completion, setCompletion] = useState(\"\");\n\n  const handleResponse = async (response: Response) => {};\n\n  const handleChange = (e: ChangeEvent<HTMLInputElement>) => {\n    setPrompt(e.target.value);\n  };\n\n  const handleSubmit = () => fetchCompletion(prompt)\n    .then(handleResponse)\n\n  return (\n    <div>\n      <div>\n        <input type=\"text\" value={prompt} onChange={handleChange} />\n        <button type=\"button\" onClick={handleSubmit}>Submit</button>\n      </div>\n      <p>{completion}</p>\n    </div>\n  );\n}\n```\n\n2. Convert OpenAI stream to ReadableStream. OpenAI sends a stream of bytes. We need to convert that to a stream of strings.\n\n```javascript\n...\n\nconst Chatbot = () => {\n  ...\n\n  const handleResponse = async (response: Response) => {\n    const stream = response.body;\n    const textStream = stream.pipeThrough(new TextDecoderStream());\n  }\n\n  ...\n}\n```\n\n3. Make ReadableStream async iterable. ReadableStream is not yet an async iterable in browsers, so we need to convert it to one.\n   If our target platform were NodeJS we wouldn't need this step as ReadableStream is already an async iterable in NodeJS.\n\n```javascript\n  ...\n\n  // Convert the stream to an async iterator.\n  // Found here https://jakearchibald.com/2017/async-iterators-and-generators/#making-streams-iterate\n  async function* streamAsyncIterator(stream: ReadableStream) {\n    const reader = stream.getReader();\n    try {\n      while (true) {\n        const { done, value } = await reader.read();\n        if (done) return;\n        yield value;\n      }\n    } finally {\n      reader.releaseLock();\n    }\n  }\n\n  ...\n\n  const Chatbot = () => {\n    ...\n\n    const handleResponse = async (response: Response) => {\n      const stream = response.body;\n      const textStream = stream.pipeThrough(new TextDecoderStream());\n      const asyncIteratorStream = streamAsyncIterator(textStream);\n      for await (const chunk of asyncIteratorStream) {\n        console.log(chunk);\n      }\n    }\n\n    ...\n  }\n```\n\n4. Previously we were logging each chunk to the console. Now we need to parse each chunk as an event. We'll use the `eventsource-parser` package to do this.\n\n```javascript\n...\n\nimport { createParser, ParsedEvent, ReconnectInterval } from \"eventsource-parser\";\n\n...\n\nconst Chatbot = () => {\n  ...\n\n  const parseEvent = (event: ParsedEvent | ReconnectInterval) => {\n    console.log(event);\n  };\n\n  const handleResponse = async (response: Response) => {\n    ...\n    const parser = createParser(parseEvent);\n    for await (const chunk of asyncIteratorStream) {\n      parser.feed(chunk);\n    }\n  }\n\n  ...\n}\n\n```\n\n5. Update completion text as we get each event. You should now see the completion text update as it is generated.\n\n```javascript\n...\n\nconst Chatbot = () => {\n  ...\n\n  const parseEvent = (event: ParsedEvent | ReconnectInterval) => {\n    if (event.type !== 'event' || event.data === '[DONE]') {\n      return\n    }\n\n    const delta = JSON.parse(event.data).choices[0]?.delta?.content || \"\";\n    setCompletion((prev) => {\n      if (prev) {\n        return prev + delta;\n      } else {\n        return delta;\n      }\n    });\n  };\n\n  ...\n}\n```\n\n## Recap\n\nThat's it! You should now have a working chatbot that can complete sentences in real time. You can find the full code [here](https://gist.github.com/seanbecker15/49a20ef17e77682d7907f5eba8fd507b).\n",
      "url": "https://seanbecker.me/blog/chatgpt-text-completion",
      "title": "OpenAI Series: Chat-GPT Style Completion Using SSE Streaming API",
      "summary": "Use the OpenAI SSE streaming API to make a chatbot that can complete sentences just like ChatGPT.",
      "date_modified": "2023-12-04T06:00:00.000Z"
    },
    {
      "id": "https://seanbecker.me/blog/lg-wake-on-lan",
      "content_html": "\nJust looking for code? You can find that [here](https://gist.github.com/seanbecker15/456ddec169eb68aa7e48d38234bb5283).\n\n## Background\n\nPart of the challenge while working at Fubo is that we maintain several SmartTV applications.\nIn order to reduce the overhead of maintenance we rely on tooling, one of which is the [ares-cli](https://webostv.developer.lge.com/develop/tools/cli-dev-guide).\nUnfortunately this CLI doesn't expose functionality to wake a TV up over the network, which is problematic for test automation.\nIt also means that I need to get up from my desk to turn on my TV before launching a debug version of our application.\n\n## Solution\n\nI found several sources that wake LG over the network such as\n\n- [home assistant](https://github.com/home-assistant/core/blob/2ad5b1c3a6140a49d1113e86e46b68165cf26884/homeassistant/components/wake_on_lan/__init__.py#L34C15-L34C32)\n- [LGTVCompanion](https://github.com/JPersson77/LGTVCompanion)\n\nBoth of these solutions are embedded in bigger systems so I decided take the code from [Console.cpp](https://github.com/JPersson77/LGTVCompanion/blob/5c63223a9866bc11965a3d9c9240313694c9c3f6/LGTV%20Companion%20Console/Console.cpp#L1531) and convert it to javascript.\nThis can be quickly ported to another language using a good LLM like ChatGPT or Claude.\n\nYou can find the javascript code [here](https://gist.github.com/seanbecker15/456ddec169eb68aa7e48d38234bb5283).\n",
      "url": "https://seanbecker.me/blog/lg-wake-on-lan",
      "title": "LG TV Wake on LAN",
      "summary": "NodeJS script to wake LG (WebOS) TV over LAN",
      "date_modified": "2024-06-21T05:00:00.000Z"
    },
    {
      "id": "https://seanbecker.me/blog/professional-experience",
      "content_html": "\n## FuboTV - Senior Software Engineer (2022 - Present)\n\n- Migrated native video players to generic Media Source Extension (MSE) video players on Smart TV devices.\n- Built ecosystem of tools to increase team efficiency:\n  - Introduced datadog logging and instrumentation to enhance troubleshooting capabilities and gather feedback on releases.\n  - Built tool to query logs and generate metrics using ChatGPT function calls to assist with gathering performance insights.\n- [Contributed to redesigned application](https://cordcuttersnews.com/fubo-is-rolling-out-a-new-improved-user-interface-with-re-designed-apps/) (launched to 300,000+ users).\n\n## Fubo Gaming - Software Engineer (2021 - 2022)\n\n- Interviewed 70+ candidates for engineering roles. Scaled team from 5 to 15 engineers.\n- Coordinated regulatory changes required to launch Fubo Sportsbook in Iowa, Arizona, and New Jersey.\n- Rewrote authentication flow & integration between sportsbook and TV\n  product; Coordinated effort between white-label provider, in-house\n  designers, in-house frontend team, and in-house platform team.\n- Integrated [Trustly](https://us.trustly.com) payment provider, simplifying deposit flow and substantially increasing first time deposit rate.\n\n## Prior Employment\n\nFor information on prior employment, you can view my resume [here](/docs/resume.pdf).\n\nGo back [home](/).\n",
      "url": "https://seanbecker.me/blog/professional-experience",
      "title": "Professional Experience",
      "summary": "A brief summary of my professional experience.",
      "date_modified": "2024-09-14T05:00:00.000Z"
    },
    {
      "id": "https://seanbecker.me/blog/japan-trip",
      "content_html": "\n## Flights\n\n- **Joey**: Arrive May 10, 2:45 PM NRT | Depart May 24, 4:30 PM NRT\n- **Sean**: Arrive May 10, 3:25 PM NRT | Depart May 24, 2:55 PM NRT\n\n---\n\n## Saturday, May 10 — Tokyo\n\n**Booked**\n\n- Stay: Far East Village Hotel Tokyo, Asakusa — [Google Maps: 1-11-6 Asakusa, Taito-ku, Tokyo](https://www.google.com/maps/search/?api=1&query=1-11-6+Asakusa,+Taito-ku,+Tokyo,+Japan,+111-0032)\n- 5:00 PM – Arrive & check in\n- 6:35 PM – Sunset at [Tokyo Skytree](https://www.google.com/maps/search/?api=1&query=Tokyo+Skytree)\n\n_Optional_\n\n- Imperial Palace East Gardens — [Google Maps](https://www.google.com/maps/search/?api=1&query=Imperial+Palace+East+Gardens)\n- Tsukiji Outer Market — [Google Maps](https://www.google.com/maps/search/?api=1&query=Tsukiji+Outer+Market)\n\n---\n\n## Sunday, May 11 — Tokyo\n\n**Booked**\n\n- Stay: Far East Village Hotel Tokyo, Asakusa — [Maps link above]\n- 10:00 AM – [Tokyo Free Walking Tour](https://www.tokyolocalized.com/free-walking-tour)\n- 6:00 PM – Omakase in Ginza (reservation) — [Google Maps: Ginza](https://www.google.com/maps/search/?api=1&query=Ginza,+Tokyo)\n\n_Optional_\n\n- [teamLab Borderless](https://borderless.teamlab.art)\n- [Shinjuku Night Walking Tour](https://www.tokyolocalized.com/tokyo-night-walking-tour-shinjuku-kabukicho)\n\n---\n\n## Monday, May 12 — Tokyo → Kyoto\n\n**Booked**\n\n- Morning – [Sumida River Cruise](https://www.suijobus.co.jp/en/)\n- Late AM – [teamLab Planets](https://teamlabplanets.dmm.com/en/)\n- Afternoon – Shinkansen to Kyoto\n- Stay: Rinn Gion Kenninji — [Google Maps](https://www.google.com/maps/search/?api=1&query=Rinn+Gion+Kenninji,+Kyoto)\n\n_Optional_\n\n- [Fushimi Inari Taisha](https://inari.jp/en/)\n- [Nijo Castle](https://www.city.kyoto.lg.jp/sankan/page/0000004002.html)\n- Nishiki Market — [Google Maps](https://www.google.com/maps/search/?api=1&query=Nishiki+Market)\n\n---\n\n## Tuesday, May 13 — Kyoto\n\n**Booked**\n\n- Stay: Rinn Gion Kenninji — [Maps link above]\n- Morning – [Arashiyama Bamboo Grove](https://www.google.com/maps/search/?api=1&query=Arashiyama+Bamboo+Grove)\n\n_Optional_\n\n- [Samurai Museum](https://www.samuraimuseum.jp/en/)\n- Tea ceremony & kimono rental\n\n---\n\n## Wednesday, May 14 — Kyoto\n\n**Booked**\n\n- Stay: Rinn Gion Kenninji — [Maps link above]\n- Morning – Kuya-no-taki Waterfall hike — [InsideKyoto guide](https://www.insidekyoto.com/takao-hozukyo-hike-via-kiyotaki-kuya-no-taki-waterfall)\n\n_Optional_\n\n- [Yamazaki Whisky Distillery](https://www.suntory.com/factory/yamazaki/)\n\n---\n\n## Thursday, May 15 — Kyoto\n\n**Booked**\n\n- Stay: Rinn Gion Kenninji — [Maps link above]\n- All day – Wander the Gion area\n\n_Optional_\n\n- Fushimi Inari Taisha\n- Nijo Castle\n- Nishiki Market\n- Samurai Museum\n\n---\n\n## Friday, May 16 — Hiroshima → Miyajima\n\n**Booked**\n\n- Morning – Shinkansen to Hiroshima & visit [Peace Memorial Museum](https://hpmmuseum.jp/?lang=en)\n- 3:00 PM – Check in at Iwaso Ryokan — [Google Maps](https://www.google.com/maps/search/?api=1&query=Iwaso+Ryokan+Miyajima)\n- Evening – Onsen & kaiseki dinner\n\n_Optional_\n\n- Hiroshima Castle — [Google Maps](https://www.google.com/maps/search/?api=1&query=Hiroshima+Castle)\n- Itsukushima Shrine (Miyajima) — [Google Maps](https://www.google.com/maps/search/?api=1&query=Itsukushima+Shrine)\n\n---\n\n## Saturday, May 17 — Miyajima → Osaka\n\n**Booked**\n\n- Morning – Miyajima sightseeing (Itsukushima Shrine & Mt. Misen)\n- Afternoon – Shinkansen to Osaka; check in at Agora Place Osaka Namba — [Google Maps](https://www.google.com/maps/search/?api=1&query=Agora+Place+Osaka+Namba)\n- Evening – [Dōtonbori](https://www.google.com/maps/search/?api=1&query=Dotonbori+Osaka)\n\n_Optional_\n\n- Minayoshi sushi in Kadoma — [Google Maps](https://www.google.com/maps/search/?api=1&query=Minayoshi+Kadoma)\n- Tenjinbashi-suji arcade — [Google Maps](https://www.google.com/maps/search/?api=1&query=Tenjinbashi-suji)\n- Bunraku theatre — [Google Maps](https://www.google.com/maps/search/?api=1&query=Bunraku+Theatre+Osaka)\n\n---\n\n## Sunday, May 18 — Nara day-trip\n\n**Booked**\n\n- Morning – [Tōdai-ji & Deer Park](https://www.google.com/maps/search/?api=1&query=Todai-ji+Nara)\n- Afternoon – [Kasuga Taisha](https://www.google.com/maps/search/?api=1&query=Kasuga+Taisha+Nara) & Nara-machi\n- Evening – Return to Osaka (stay above)\n\n_Optional_\n\n- [Himeji Castle](https://www.google.com/maps/search/?api=1&query=Himeji+Castle)\n\n---\n\n## Monday, May 19 — Osaka\n\n**Booked**\n\n- Stay: Agora Place Osaka Namba — [Maps link above]\n\n_Optional_\n\n- Himeji Castle\n- [Osaka Castle](https://www.google.com/maps/search/?api=1&query=Osaka+Castle)\n- [Kuromon Market](https://www.google.com/maps/search/?api=1&query=Kuromon+Market)\n- [Kōshien Stadium](https://www.google.com/maps/search/?api=1&query=Koshien+Stadium)\n\n---\n\n## Tuesday, May 20 — Osaka → Kobe dinner\n\n**Booked**\n\n- Kobe beef dinner — [Kobe Beef Association](https://www.kobe-niku.jp/en/top.html)\n\n_Optional_\n\n- [Kobe Harborland](https://www.google.com/maps/search/?api=1&query=Kobe+Harborland)\n- [Mount Rokko night view](https://www.google.com/maps/search/?api=1&query=Mount+Rokko)\n\n---\n\n## Wednesday, May 21 — Osaka → Tokyo\n\n**Booked**\n\n- Travel to Tokyo; check in at Shinjuku Kuyakusho-mae Capsule Hotel — [Google Maps](https://www.google.com/maps/search/?api=1&query=Shinjuku+Kuyakusho-mae+Capsule+Hotel)\n- 7:00 PM – [Shinjuku Night Walking Tour](https://www.tokyolocalized.com/tokyo-night-walking-tour-shinjuku-kabukicho)\n\n_Optional_\n\n- Golden Gai bar hop — [Google Maps](https://www.google.com/maps/search/?api=1&query=Golden+Gai+Shinjuku)\n- VR arcade\n\n---\n\n## Thursday, May 22 — Tokyo\n\n**Booked**\n\n- Morning – [teamLab Borderless](https://borderless.teamlab.art)\n- 6:00 PM – Yomiuri Giants game — [Google Maps: Tokyo Dome](https://www.google.com/maps/search/?api=1&query=Tokyo+Dome)\n\n_Optional_\n\n- [Meiji Shrine](https://www.google.com/maps/search/?api=1&query=Meiji+Shrine)\n- [Takeshita Street, Harajuku](https://www.google.com/maps/search/?api=1&query=Takeshita+Street)\n- Omotesando cafés\n\n---\n\n## Friday, May 23 — Tokyo\n\n**Booked**\n\n- Morning – [Sumida River Cruise](https://www.suijobus.co.jp/en/)\n- 6:00 PM – Natsu Basho at Ryōgoku Kokugikan (tickets secured) — [Google Maps](https://www.google.com/maps/search/?api=1&query=Ryogoku+Kokugikan)\n\n_Optional_\n\n- Tsukiji Outer Market\n- Whisky bar crawl (e.g. Bar High Five)\n\n---\n\n## Saturday, May 24 — Departure\n\n**Booked**\n\n- Flight home\n\n_Optional_\n\n- Last-minute shopping\n",
      "url": "https://seanbecker.me/blog/japan-trip",
      "title": "Japan Trip Itinerary",
      "summary": "May 10 – May 24, 2025",
      "date_modified": "2025-04-20T05:00:00.000Z"
    },
    {
      "id": "https://seanbecker.me/blog/claiming-my-own-at-handle",
      "content_html": "\nAfter reading [Dan Abramov’s post](https://overreacted.io/where-its-at/) about the AT Protocol, I became curious about how identity works on Bluesky. Using [atproto-browser.vercel.app](https://atproto-browser.vercel.app/), I realized how simple it is to connect your own domain to your account. My profile now lives at **at://seanbecker.me**.\n\n## Steps\n\n### 1. Find your DID\n\nGo to [https://atproto-browser.vercel.app/](https://atproto-browser.vercel.app/) and look up your existing Bluesky handle, in my case `seanbex.bsky.social`.\nMy DID is:\n\n```\ndid:plc:p2epzw3sltq7tdsg7sn7qenr\n```\n\n### 2. Add the `.well-known` verification file\n\nOn your website, create a file at:\n\n```\nhttps://seanbecker.me/.well-known/atproto-did\n```\n\nThe file should contain only your DID:\n\n```\ndid:plc:p2epzw3sltq7tdsg7sn7qenr\n```\n\nMake sure there are no extra spaces or newlines.\n\n### 3. Update your handle in Bluesky\n\nIn the Bluesky app or on the web:\n\n- Go to **Settings → Change handle**\n- Select **I have my own domain**\n- Enter `seanbecker.me`\n\nBluesky will check the `.well-known` file and update your handle once verified.\n\n## Closing thoughts\n\nThe AT Protocol makes it possible to manage your online identity under your own domain, independent of any specific platform. It’s a small change that makes the web feel a little more open again.\n\nThanks to [Dan Abramov](https://overreacted.io) for the inspiration to explore this.\n",
      "url": "https://seanbecker.me/blog/claiming-my-own-at-handle",
      "title": "Claiming My Own AT Protocol Handle (at://seanbecker.me)",
      "summary": "How I connected my Bluesky account to my own domain using the AT Protocol.",
      "date_modified": "2025-10-04T00:00:00.000Z"
    },
    {
      "id": "https://seanbecker.me/blog/keeping-fantasy-alive",
      "content_html": "\nSource code found on [GitHub](https://github.com/seanbecker15/cbs-fantasy-tooling).\n\nIn 2020, CBS Sports changed their UI and broke a workflow my family had relied on for years.\n\nNothing dramatic happened at once. The site still worked. Picks still showed up. But a small detail changed under the hood. HTML tables were replaced with deeply nested divs, and copy and paste stopped behaving the way it always had.\n\nWhat used to take about 5 to 10 minutes each week suddenly took close to an hour. Every Tuesday. For a fantasy football league that had already been running for nearly two decades, that friction mattered more than it sounds.\n\nThis repository exists for one reason: to keep a long-running league accurate, fair, and fun without forcing anyone to change how they participate.\n\nNo new accounts.  \nNo new platform.  \nNo retraining required.\n\n---\n\n## A League With History\n\nOur league started in 2004. At first it was fully manual. Picks were written down and scores were tracked by hand. Eventually it moved to CBS Sports, but the league never really fit the default Pick’em mold.\n\nOver time we added custom rules, weekly bonuses, and manual verification steps. Those rules became part of the league’s identity. They also made scoring more complicated than what CBS supported out of the box.\n\nFor years, that gap was handled with spreadsheets and process. It worked well enough until it didn’t.\n\n---\n\n## What Kind of League This Is\n\nThis is a confidence pool.\n\nAt a high level:\n\n- Each week, participants pick the winner of every NFL game\n- Each pick is assigned a unique confidence value\n- Correct picks earn points equal to that confidence\n- Incorrect picks earn zero\n\nThe strategy is not just about picking winners. It is about deciding where to place confidence relative to your other picks.\n\nOn top of that, we have a couple of extra rules that materially affect standings:\n\n- **Most Wins Bonus**  \n  The participant with the most correct picks in a week gets 5 bonus points\n\n- **Most Points Bonus**  \n  The participant with the highest total confidence points gets 10 bonus points  \n  Ties are broken using the Monday Night Football total score\n\nThese bonuses are simple to explain but annoying to calculate, especially when you are doing it by hand every week.\n\n---\n\n## Why We Didn’t Switch Platforms\n\nFrom a technical perspective, switching platforms or building something custom would have been easier.\n\nFrom a practical perspective, it would have killed the league.\n\nThis is a group of family and family friends. Some people have been participating for decades. Asking everyone to create new accounts, learn a new UI, and change habits they have had for years would have created a lot of friction.\n\nCBS Sports already hosts the league and it works well enough for picks. The goal was never to replace it. The goal was to work around its limitations.\n\nCBS stays the system of record.\n\n---\n\n## The Spreadsheet Workflow\n\nFor a long time, my father handled scoring using an Excel spreadsheet with carefully built formulas. It supported:\n\n- confidence scoring\n- weekly bonuses\n- tie breakers\n- audits before results were finalized and emailed out\n\nThe weekly flow looked like this:\n\n1. Copy results from CBS Sports\n2. Paste them into Excel\n3. Verify the math\n4. Send out standings\n\nFrom roughly 2010 through 2020, this took very little time. The process was stable and predictable.\n\nAfter the CBS UI change, it wasn’t. Data pasted into the wrong columns. Rows would shift. Sometimes values were just missing. The same task now took close to an hour and required way more manual cleanup.\n\nThat was not sustainable.\n\n---\n\n## The First Fix\n\nThe first version of this project was intentionally narrow in scope.\n\nI built a scraper that pulled league results directly from CBS Sports, normalized the data, and fed it back into the existing spreadsheet.\n\nThe spreadsheet stayed on purpose.\n\nMy father is an auditor by trade. Being able to review and spot check numbers before publishing results is non negotiable. He also genuinely enjoys that part of the process. The goal was not to replace him. It was to remove the brittle steps that had started breaking.\n\nAutomation supported the workflow instead of taking it over.\n\nThat scraper has now been running weekly for three seasons and has been boring in the best possible way.\n\n---\n\n## Why the Project Grew\n\nOnce reliable data ingestion existed, it was hard not to keep going.\n\nWith clean data available, new ideas became possible:\n\n- combining historical league results with Vegas odds\n- experimenting with different confidence allocation strategies\n- building charts just to see what patterns show up\n- creating APIs for live leaderboards and custom UIs\n\nAt that point, the project stopped being just a scraper. It turned into a place to experiment with automation and analysis around something we already cared about.\n\nCBS Sports still stays the source of truth.\n\n---\n\n## What This Repository Does\n\nAt a high level, this project:\n\n- ingests NFL and league data from multiple sources\n- normalizes and analyzes that data\n- feeds results into emails, charts, databases, and real time views\n\nAll without requiring league members to change platforms or behavior.\n\n---\n\n## What Comes Next\n\nThis post focused on why the project exists.\n\nFuture posts will dig into:\n\n- how a broken manual workflow was automated without disrupting people\n- how league history and Vegas odds can be combined to experiment with weekly picks\n- how the same data pipeline powers charts, APIs, and live standings\n\nEverything builds on the same idea: automate the fragile parts and keep humans in the loop where it matters.\n\n---\n\n## Thanks for Reading\n\nThis started as a small fix to keep a long running league operational and slowly grew into a place to experiment with data, automation, and analysis.\n\nIf you want to talk through any of the specifics, scoring rules, ingestion details, or design tradeoffs, you can reach me at:\n\n- GitHub: https://github.com/seanbecker15\n- X: https://x.com/theseanbecker\n- Email: sean.becker15@gmail.com\n\nMore detailed posts will follow as each part of the system is explored in depth.\n",
      "url": "https://seanbecker.me/blog/keeping-fantasy-alive",
      "title": "Keeping a 20-Year Fantasy Football League Alive",
      "summary": "How a small UI change broke a long-standing workflow and how automation fixed it without forcing anyone to change behavior.",
      "date_modified": "2025-12-15T06:00:00.000Z"
    },
    {
      "id": "https://seanbecker.me/blog/rio-trip",
      "content_html": "\n## Flights\n\n- **Sean**: Arrive Feb 10, 8:15 AM ORD -> ATL -> RIO | Depart Feb 19, 9:30 PM RIO -> ATL -> ORD\n\n## Accommodation\n\n- [Windsor Plaza Copacabana\n  Ave Princesa Isabel 263 Copacabana, Rio de Janeiro, Brazil, 22011-010](https://www.google.com/maps/place/Windsor+Plaza+Copacabana/@-22.9627805,-43.1776329,17z/data=!4m9!3m8!1s0x997fff867cdf99:0x97e28a466acef850!5m2!4m1!1i2!8m2!3d-22.9627855!4d-43.175058!16s%2Fg%2F1tzl_5js?entry=ttu&g_ep=EgoyMDI2MDIwNC4wIKXMDSoASAFQAw%3D%3D)\n- Check in @ 3pm on Tuesday, 2/10\n\n## Other notes\n- Erik's notion: [https://www.notion.so/Rio-Carnaval-2026-Homepage](https://www.notion.so/Rio-Carnaval-2026-Homepage-27b4964af572802cb854c206e450ed57)\n- Guys' Airbnb: [Avenida Nossa Senhora de Copacabana, 198 201](https://www.google.com/maps/place/Av.+Nossa+Sra.+de+Copacabana,+198+-+201+-+Copacabana,+Rio+de+Janeiro+-+RJ,+22020-001,+Brazil/@-22.9651068,-43.179705,17z/data=!3m1!4b1!4m5!3m4!1s0x9bd5550a82deb5:0x1d699e4466dd1fd1!8m2!3d-22.9651118!4d-43.1771301?entry=ttu&g_ep=EgoyMDI2MDIwNC4wIKXMDSoASAFQAw%3D%3D)\n- Gals' Airbnb: [Av. Atlântica, 2440 - Copacabana](google.com/maps/place/Av.+Atlântica,+2440+-+Copacabana,+Rio+de+Janeiro+-+RJ,+22041-001,+Brazil/@-22.9665498,-43.1809603,16.37z/data=!4m6!3m5!1s0x9bd54557ccde0b:0x8acaa63907e9ce75!8m2!3d-22.9713186!4d-43.1847121!16s%2Fg%2F11j8sdh6v2?entry=ttu&g_ep=EgoyMDI2MDIwNC4wIKXMDSoASAFQAw%3D%3D)\n\n---\n\n## Tuesday, Feb 10\n\n**Booked**\n\n- Check in @ 3pm [Windsor Plaza Copacabana](https://www.google.com/maps/place/Windsor+Plaza+Copacabana/@-22.9627805,-43.1776329,17z/data=!4m9!3m8!1s0x997fff867cdf99:0x97e28a466acef850!5m2!4m1!1i2!8m2!3d-22.9627855!4d-43.175058!16s%2Fg%2F1tzl_5js?entry=ttu&g_ep=EgoyMDI2MDIwNC4wIKXMDSoASAFQAw%3D%3D)\n\n_Optional_\n\n---\n\n## Wednesday, Feb 11\n\n**Booked**\n\n_Optional_\n\n---\n\n## Thursday, Feb 12\n\n**Booked**\n\n_Optional_\n\n---\n\n## Friday, Feb 13\n\n**Booked**\n\n- BOMA presents: Jamie Jones, Adam Ten, & Mita Gami\n  - Time: 10pm\n  - Address: [Museu do Amanhã, Rio de Janeiro - RJ](https://www.google.com/maps/place/Museu+do+Amanh%C3%A3,+Rio+de+Janeiro+-+RJ/data=!4m2!3m1!1s0x997f5732a12a31:0x316901f971660ce1?sa=X&ved=1t:155783&ictx=111)\n  - App: Ingresse\n\n_Optional_\n\n---\n\n## Saturday, Feb 14\n\n**Booked**\n\n- Rio Carnaval: Sambadrome parades\n  - VIP access (Camarote MAR)\n  - App: Quentro\n  - Requires us to pick up shirts and verify facial recognition ahead of time\n    - Kit pickup address: [Jockey Club Brasileiro – Tribuna Praça Santos Dumont, 31 – Gávea, Rio de Janeiro](https://www.google.com/maps/place/Jockey+Club+Brasileiro/@-22.9808712,-43.236486,14.64z/data=!4m6!3m5!1s0x9bd5a4a2deac4b:0xb3e7dcff9fe1c860!8m2!3d-22.9735236!4d-43.2247015!16s%2Fg%2F122c1d3s?entry=ttu&g_ep=EgoyMDI2MDIwNC4wIKXMDSoASAFQAw%3D%3D)\n    - Kit pickup time: 2pm-10pm every day we're there\n    - Source: [email](https://mail.google.com/mail/u/0/#search/rio/FMfcgzQfBkGjDRkvtsRtCsHRjWZnLCQV)\n  - Event time: Opens at 7pm, Starts at 8pm\n  - Event address: [Marquês de Sapucaí, Rio de Janeiro](https://www.google.com/maps/place/Sambadrome+Marqu%C3%AAs+de+Sapuca%C3%AD/@-22.9114472,-43.1993789,17z/data=!3m2!4b1!5s0x997f0d0c24ef39:0x3333a5703a71abdc!4m6!3m5!1s0x997f0d91d00145:0xd0816e87c570167d!8m2!3d-22.9114522!4d-43.196804!16zL20vMGJwd3Fw?entry=ttu&g_ep=EgoyMDI2MDIwNC4wIKXMDSoASAFQAw%3D%3D)\n\n_Optional_\n\n---\n\n## Sunday, Feb 15\n\n**Booked**\n\n_Optional_\n\n---\n\n## Monday, Feb 16\n\n**Booked**\n\n_Optional_\n\n---\n\n## Tuesday, Feb 17\n\n**Booked**\n\n_Optional_\n\n---\n\n## Wednesday, Feb 18\n\n**Booked**\n\n_Optional_\n\n---\n\n## Thursday, February 19 — Departure\n\n**Booked**\n\n- Hotel check out @ 12pm\n- Flight departs @ 9:30 PM\n\n_Optional_\n\n- Last-minute shopping\n",
      "url": "https://seanbecker.me/blog/rio-trip",
      "title": "Rio Trip Itinerary",
      "summary": "Feb 10 – Feb 19, 2026",
      "date_modified": "2026-02-08T06:00:00.000Z"
    }
  ]
}
